# WARNING - Generated by {fusen} from /dev/flat_dev.Rmd: do not edit by hand

#' @title Plotting Open Text variables
#' @param datapath path to the file with the data format as extracted from kobo with dot as group separator and xml header
#' @param xlsformpath path to the xlsform file used to cole
#' @param var name of the variable to display
#' @param showcode display the code
#' @export

#' @examples
#' plot_text(datapath = system.file("data.xlsx", package = "kobocruncher"),
#'               xlsformpath =  system.file("sample_xlsform.xlsx", package = "kobocruncher"), 
#'               var = "profile.occupation")
plot_text <- function(datapath = datapath, 
                      xlsformpath = xlsformpath,
                      var, 
                      showcode = FALSE) {
  
  dico <-  kobo_dico(xlsformpath = xlsformpath)
  datasource <- as.character(  dico[3][[1]]$form_title ) 
  data <- kobo_frame(datapath = datapath,
                   xlsformpath = xlsformpath,
                   var = var  )
  # cat("---\n")
  # cat("\n\n")
  #cat( stringr::str_wrap(  paste0(  label_varname(var), " (Open Text question)"), 70) )
  # cat(paste("####", label_varname(var)))
  # cat("\n\n")
  #cat("Open Text question\n\n")
  
  rr <- mean(!is.na(data[[var]]))
  require("tm")
  #Replacing “/”, “@” and “|” with space:
  toSpace <- tm::content_transformer(function (x , pattern ) gsub(pattern, " ", x))  
  # Cleaning the text  #### 
  docs <-  tm::Corpus(tm::VectorSource(data[[var]]))  %>%
            #Text transformation to replace special characters from the text.
            tm::tm_map(., toSpace, "/")  %>%
            tm::tm_map(., toSpace, "@")  %>%
            tm::tm_map(., toSpace, "\\|")  %>%
            # Convert the text to lower case
            tm::tm_map(., content_transformer(tolower))  %>%
            # Remove numbers
            tm::tm_map(., removeNumbers)  %>%
            # Remove punctuations
            tm::tm_map(.,  removePunctuation)  %>%
            # Eliminate extra white spaces
            tm::tm_map(.,  stripWhitespace)  %>%
            # Text stemming - reduces words to their root form.
            tm::tm_map(.,  stemDocument)  %>%
            # Remove common stopwords depending on language
            # The information value of ‘stopwords’ is near zero due to the fact that they 
            # are so common in a language. Removing this kind of words is useful before
            # further analyses. 
            tm::tm_map(., removeWords, stopwords("english"))  %>%
            # Remove your own stop word
            tm::tm_map(., removeWords, c("blabla1", "blabla2")) 
  
    # Step 4 : Build a term-document matrix ####
    # Table containing the frequency of the words. Column names are words and row names are documents. 
    dtm <- tm::TermDocumentMatrix(docs)
    m <- as.matrix(dtm)
    v <- sort(rowSums(m),decreasing=TRUE)
    d <- data.frame(word = names(v),freq=v)
    #head(d, 10)
  
    ## Put a condition in case there's no record
    if(nrow(d) > 0 ) {
      
        ## Writing code instruction in report
        if( showcode == TRUE) {
          #cat("---\n")
          
          cat(paste0("  `plot_text(\"", var, "\")`  \n\n"))} 
          # cat(paste0("##### ",fontawesome::fa_png("far fa-copy", fill ="grey"), "  `plot_text(\"", var, "\")`  "))
          # cat("\n\n") } 
        else {}
      
      # Step 5 : Generate the Word cloud  ####
      #The importance of words can be illustrated as a word cloud as follow :
      set.seed(1234)
      wordcloud::wordcloud(words = d$word, # words : the words to be plotted
                                freq = d$freq,  # freq : their frequencies
                                min.freq = 1,  # min.freq : words with frequency below min.freq will not be plotted
                                max.words=200, # max.words : maximum number of words to be plotted
                                random.order=FALSE, # random.order : plot words in random order. If false, they will be plotted in decreasing frequency
                                rot.per=0.25,   # rot.per : proportion words with 90 degree rotation (vertical text)
                                colors= RColorBrewer::brewer.pal(8, "Dark2")) # colors : color words from least to most frequent. Use, for example, colors =“black” for single color.
    title( main = stringr::str_wrap( label_varname(xlsformpath = xlsformpath, 
                                                  x= var), 70),
           sub = glue::glue("Open Text question \n Source: {datasource}" ))  
    
         
      # p1 <- ggplot(d, 
      #              aes(label = word,
      #                  size = freq,
      #                  color = freq )) +
      #       ggwordcloud::geom_text_wordcloud(area_corr = TRUE,
      #                                        rm_outside = TRUE,
      #                                        eccentricity = 1) +
      #       scale_size_area(max_size = 50) +
      #       # scale_radius(range = c(0, 10),  limits = c(0, NA)) +
      #       scale_color_gradient(low = "darkred", high = "red") +
      #       labs(x = NULL, y = NULL,
      #        title = str_wrap(survey_label(var), 60), 
      #        subtitle = if (!is.na(label_varhint(var))){ 
      #          stringr::str_wrap(label_varhint(var), 70)} else { ""},
      #        caption = glue::glue("Wordcloud displaying an Open Text question, Response rate = {scales::label_percent(accuracy = .01)(rr)} on a total of {nrow(data)} records")) +
      #   
      #       theme_minimal( base_size = 13)  
      # print(p1)
      
    
  } else { cat("<strong style=\"color:#0072BC;\">No significant text for this specific question!</strong>\n\n")}
  
  # cat("\n\n")
}

