---
title: "Automatic Data Exploration Step"
date: " `r format(Sys.Date(),  '%d %B %Y')`"
output:
  koboloadeR::template_exploration:
    toc: true
    toc_depth: 2
    toc_float: true
params:
  datafolder: "data-raw"
  data: "data.xlsx"
  form: "form.xlsx"
  crosstab: ""
  datasource: ""
---

<!--
How to: This is a simple exploration notebook for any data collected on kobo -
1. Create an Rstudio project
2. Open this Rmd Template
3. create a new folder named "data-raw" 
4. get both your form and data from your kobo project and put them within this "data-raw" folder - Note that data shall be saved as csv with "XML Value and header format". use advanced options to set up "Include groups in headers" and use "." as group separator
5. Replace the correct reference in the params of this notebook nd Knit your notebook 

Note: by default this notebook will take the first label translation (English, Spanish, etc.) by order in your form - if you want to get the results in a different language - just adjust the order within the xlsform - You can also adjust the label directly in your xlsform to regenerate the crunching report 
-->


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE,
                      comment = '', 
                      # fig.width = 5.5, fig.height = 4,
                      fig.retina = 2, 
                      fig.width = 8,
                      fig.asp = 0.618,
                      fig.align = "center",
                      dev = "ragg_png",
                      out.width = "90%")

extrafont::loadfonts(quiet=TRUE)
options(scipen = 999) # turn-off scientific notation like 1e+48

library("koboloadeR")
datapath <- here::here(params$datafolder, params$data)
xlsformpath <- here::here(params$datafolder, params$form) 

```


```{r cleandata}

## When iterating during the initial data exploration, you may add here specific cleaning steps 


```

```{r calculation}

## When iterating during the initial data exploration, you may create here calculated variables


```

# Crunching step

This data crunching report allows to quickly explore the results of the survey that can be regenerated as needed. The objective of this report is to allow to quickly identify potential patterns in your dataset. A quick screening of this initial report should allow to select the most meaningful graphs.

The crunching process produces a lot of visuals. Therefore it is key to carefully select the most relevant visual that will be presented for potential interpretation in the next step. A typical data interpretation session shall not last more than 2hours and include more than 60 visuals to look at in order to keep participants with a good focus level.
 
In order to guide this selection phase, data experts, in collaboration with the data analysis group, can use the following elements:
 
  *  For numeric value, check the frequency distributions of each variable to average, deviation, including outlier and oddities
 
  *  For categorical variables, check for unexpected values: any weird results based on common sense expectations
 
  *  Use correlation analysis to check for potential contradictions in respondents answers to different questions for identified associations (chi-square)
 
  *  Always, Check for missing data (NA) or "%of respondent who answered" that you cannot confidently explain
 
  *  Check unanswered questions, that corresponds to unused skip logic in the questionnaire: For instance, did a person who was never displaced answer displacement-related questions? Were employment-related answers provided for a toddler?
 
When analyzing those representations in a collective setting during data interpretation sessions, you may:  
 
  *  __Reflect__: question data quality and/or make suggestions to adjust questions, identify additional cleaning steps;   

  *  __Interpret__: develop qualitative interpretations of data patterns;     

  *  __Recommend__: suggest recommendations in terms of programmatic adjustment;    

  *  __Classify__: define level of sensitivity for certain topics if required;     

The report can be regenerated as needed by:  

  *  adjusting the report configuration in the xlsform to break it into report and chapter;   

  *  configuring disaggregation & correlation for each question;   

  *  revising the data cleansing based on the cleaning log;   
 
  *  appending calculated indicators to your data frame to reshape variable - also called feature engineering. 


# Automatic Exploration

```{r  }
## The 2 lines below are for the demo - please comment the 2 below 
# and uncomment the one after once you have set up your report parameters..
datapath <- system.file("data.xlsx", package = "koboloadeR")
xlsformpath <-  system.file("sample_xlsform.xlsx", package = "koboloadeR")
# datapath <- params$data
# xlsformpath <-  params$form 

dico <- kobo_dico(xlsformpath = xlsformpath)
questions <- as.data.frame(dico[1])
crunchingparameters <- list(datapath = datapath,
                         xlsformpath =  xlsformpath,
                         type = questions$type,
                         name =  questions$name,
                         showcode = TRUE)
```


```{r cruncher, results='asis' }
# Map over multiple inputs simultaneously
# https://purrr.tidyverse.org/reference/map2.html
purrr::pwalk(crunchingparameters,
             kobo_cruncher)



```


